{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f22767bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09ed4542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f6654de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e503536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28913a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\"AI4Protein/ProSST-2048\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"AI4Protein/ProSST-2048\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8b02278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method SpecialTokensMixin.add_tokens of EsmTokenizer(name_or_path='AI4Protein/ProSST-2048', vocab_size=25, model_max_length=2048, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<eos>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'cls_token': '<cls>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<cls>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"<eos>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t23: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t24: AddedToken(\"<mask>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9defa08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_seq(fasta):\n",
    "    for record in SeqIO.parse(fasta, \"fasta\"):\n",
    "        return str(record.seq)\n",
    "\n",
    "\n",
    "def tokenize_structure_sequence(structure_sequence):\n",
    "    shift_structure_sequence = [i + 3 for i in structure_sequence]\n",
    "    shift_structure_sequence = [1, *shift_structure_sequence, 2]\n",
    "    return torch.tensor(\n",
    "        [\n",
    "            shift_structure_sequence,\n",
    "        ],\n",
    "        dtype=torch.long,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaed777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6c0c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "residue_sequence_dir = \"/home/yining_yang/Documents/lm/SSRAP/VenusREM/data/proteingym_v1/aa_seq\"\n",
    "structure_sequence_dir = \"/home/yining_yang/Documents/lm/SSRAP/VenusREM/data/proteingym_v1/struc_seq/2048\"\n",
    "name = \"A0A2Z5U3Z0_9INFA_Wu_2014\"\n",
    "\n",
    "residue_fasta = Path(residue_sequence_dir) / f\"{name}.fasta\"\n",
    "structure_fasta = Path(structure_sequence_dir) / f\"{name}.fasta\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6310c100",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = read_seq(residue_fasta)\n",
    "structure_sequence = read_seq(structure_fasta)\n",
    "\n",
    "structure_sequence = [int(i) for i in structure_sequence.split(\",\")]\n",
    "ss_input_ids = tokenize_structure_sequence(structure_sequence).to(device)\n",
    "tokenized_results = tokenizer([sequence], return_tensors=\"pt\")\n",
    "input_ids = tokenized_results[\"input_ids\"].to(device)\n",
    "attention_mask = tokenized_results[\"attention_mask\"].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9550852c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 567])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65ff546f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"MKAKLLVLLYAFVATDADTICIGYHANNSTDTVDTILEKNVAVTHSVNLLEDSHNGKLCKLKGIAPLQLGKCNITGWLLGNPECDSLLPARSWSYIVETPNSENGACYPGDLIDYEELREQLSSVSSLERFEIFPKESSWPNHTFNGVTVSCSHRGKSSFYRNLLWLTKKGDSYPKLTNSYVNNKGKEVLVLWGVHHPSSSDEQQSLYSNGNAYVSVASSNYNRRFTPEIAARPKVRDQHGRMNYYWTLLEPGDTIIFEATGNLIAPWYAFALSRGFESGIITSNASMHECNTKCQTPQGAINSNLPFQNIHPVTIGECPKYVRSTKLRMVTGLRNIPSIQYRGLFGAIAGFIEGGWTGMIDGWYGYHHQNEQGSGYAADQKSTQNAINGITNKVNSVIEKMNTQFTAVGKEFNNLEKRMENLNKKVDDGFLDIWTYNAELLVLLENERTLDFHDLNVKNLYEKVKSQLKNNAKEIGNGCFEFYHKCDNECMESVRNGTYDYPKYSEESKLNREKIDGVKLESMGVYQILAIYSTVASSLVLLVSLGAISFWMCSNGSLQCRICI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48222594",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        ss_input_ids=ss_input_ids,\n",
    "        labels=input_ids,\n",
    "        output_hidden_states=True,\n",
    "        # output_attentions=True,  # Make sure to get attention outputs\n",
    "        return_dict=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24045199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs.hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8435d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_embedding = outputs.hidden_states[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2052e057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 567, 768])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_embedding.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "626c3646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mutant  DMS_score  DMS_score_bin  VenusREM\n",
      "0      A46C   0.503519              1 -1.188972\n",
      "1      A46D   0.162813              1 -0.495420\n",
      "2      A46E   0.374461              1 -0.268819\n",
      "3      A46F  -0.051768              1 -0.995978\n",
      "4      A46G  -0.405567              0 -0.798013\n",
      "...     ...        ...            ...       ...\n",
      "1327   W38R   0.409986              1 -0.006912\n",
      "1328   W38S  -0.026247              1 -0.241827\n",
      "1329   W38T  -0.047858              1 -0.338707\n",
      "1330   W38V   0.207099              1 -0.326499\n",
      "1331   W38Y   0.085070              1 -0.460771\n",
      "\n",
      "[1332 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# read all csv files in /home/yining_yang/Documents/lm/SSRAP/VenusREM/result/proteingym_v1_original/scores in a for loop\n",
    "# Define the directory path\n",
    "directory_path = \"/home/yining_yang/Documents/lm/SSRAP/VenusREM/result/proteingym_v1_original/scores\"\n",
    "\n",
    "# Create an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    # Check if the file ends with .csv\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        df = pd.read_csv(file_path)  # Read the CSV file\n",
    "        print(df)\n",
    "        break\n",
    "\n",
    "# Optionally combine them into one DataFrame\n",
    "# combined_df = pd.concat(dataframes, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c58e4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7c8d2b2",
   "metadata": {},
   "source": [
    "## Few shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6e42a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "fewshot_DMS_csv = '/home/yining_yang/Documents/lm/SSRAP/data/fewshot/A0A2Z5U3Z0_9INFA_Wu_2014.csv'\n",
    "# dataset = load_dataset('csv', data_files=fewshot_DMS_csv)\n",
    "# dataset = dataset['train'].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99fcdb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "class DMSDataset(Dataset):\n",
    "    def __init__(self, csv_file, sequence, structure_sequence, tokenizer):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.sequence = sequence\n",
    "        self.structure_sequence = structure_sequence\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab = tokenizer.get_vocab()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mutant = self.data.iloc[idx]['mutant']\n",
    "        dms_score = self.data.iloc[idx]['DMS_score']\n",
    "\n",
    "        # Tokenize sequence\n",
    "        # tokenized = self.tokenizer(self.sequence, return_tensors=\"pt\")\n",
    "        # input_ids = tokenized[\"input_ids\"].squeeze(0)\n",
    "        # attention_mask = tokenized[\"attention_mask\"].squeeze(0)\n",
    "\n",
    "        # Process structure sequence\n",
    "        # ss_input_ids = torch.tensor(self.structure_sequence, dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            # 'input_ids': input_ids,\n",
    "            # 'attention_mask': attention_mask,\n",
    "            # 'ss_input_ids': ss_input_ids,\n",
    "            'mutant': mutant,\n",
    "            'dms_score': torch.tensor(dms_score, dtype=torch.float)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f4adcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# # tokenizer = AutoTokenizer.from_pretrained(\"AI4Protein/ProSST-2048\", trust_remote_code=True)\n",
    "\n",
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(examples[\"mutated_sequence\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f26edd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "# class SpearmanLoss(nn.Module):\n",
    "#     def __init__(self, regularization_strength=1.0):\n",
    "#         super(SpearmanLoss, self).__init__()\n",
    "#         self.regularization_strength = regularization_strength\n",
    "\n",
    "#     def forward(self, preds, target):\n",
    "#         preds = torchsort.soft_rank(preds, regularization_strength=self.regularization_strength)\n",
    "#         target = torchsort.soft_rank(target, regularization_strength=self.regularization_strength)\n",
    "#         preds = preds - preds.mean()\n",
    "#         preds = preds / preds.norm()\n",
    "#         target = target - target.mean()\n",
    "#         target = target / target.norm()\n",
    "#         return 1 - (preds * target).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877bb0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model = AutoModelForMaskedLM.from_pretrained(\"AI4Protein/ProSST-2048\", trust_remote_code=True)\n",
    "# num_epochs =5\n",
    "# model.train()\n",
    "\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "# loss_fn = SpearmanLoss()\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     for batch in train_dataloader:\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "#         logits = outputs.logits\n",
    "#         # Compute your predictions and targets here\n",
    "#         loss = loss_fn(predictions, targets)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecf6ffab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DMSDataset(fewshot_DMS_csv, sequence, structure_sequence, tokenizer)\n",
    "# dataloader = DataLoader(dataset, batch_size=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e8b63af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the split sizes\n",
    "train_size = int(0.9 * len(dataset))  # 90% for training\n",
    "val_size = len(dataset) - train_size  # 10% for validation\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e385d0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.1986\n",
      "Validation Loss: 1.1765\n",
      "Validation Loss: 1.1556\n",
      "Validation Loss: 1.1267\n",
      "Validation Loss: 1.1298\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import itertools\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "num_epochs = 5\n",
    "# loss_fn = nn.MarginRankingLoss(margin=0.0)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "ss_input_ids = tokenize_structure_sequence(structure_sequence).to(device)\n",
    "tokenized_results = tokenizer([sequence], return_tensors=\"pt\")\n",
    "input_ids = tokenized_results[\"input_ids\"].to(device)\n",
    "attention_mask = tokenized_results[\"attention_mask\"].to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        # input_ids = batch['input_ids'].to(device)\n",
    "        # attention_mask = batch['attention_mask'].to(device)\n",
    "        # ss_input_ids = batch['ss_input_ids'].to(device)\n",
    "        # print(\"the \"+str(epoch)+\"th epoch\")\n",
    "        dms_scores = batch['dms_score'].to(device)\n",
    "        mutants = batch['mutant']\n",
    "        # print(mutants)\n",
    "        # break\n",
    "\n",
    "        batch_size = len(mutants)\n",
    "        # print(input_ids.size())\n",
    "        # print(batch_size)\n",
    "        # pred_scores = torch.tensor([0]*batch_size).to(device)\n",
    "        pred_scores=[]\n",
    "        # print(pred_scores.size())\n",
    "        # break\n",
    "        # print(ss_input_ids)\n",
    "\n",
    "        outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    ss_input_ids=ss_input_ids,\n",
    "                    labels=input_ids,\n",
    "                    # output_hidden_states=True,\n",
    "                    # # output_attentions=True,  # Make sure to get attention outputs\n",
    "                    # return_dict=True\n",
    "                )\n",
    "\n",
    "        # logits = outputs.logits\n",
    "        logits = torch.log_softmax(outputs.logits[:, 1:-1, :], dim=-1)\n",
    "        # print(logits)\n",
    "        # break\n",
    "\n",
    "        for i in range(batch_size):\n",
    "\n",
    "            pred_score = 0\n",
    "            for sub_mutant in mutants[i].split(\":\"):\n",
    "                wt, idx, mt = sub_mutant[0], int(sub_mutant[1:-1]) - 1, sub_mutant[-1]\n",
    "                score = logits[0, idx, tokenizer.convert_tokens_to_ids(mt)] - logits[0, idx, tokenizer.convert_tokens_to_ids(wt)]\n",
    "                pred_score += score\n",
    "                # print(score)\n",
    "\n",
    "                # print(pred_score)\n",
    "            # pred_scores[i] = pred_score\n",
    "            pred_scores.append(pred_score)\n",
    "\n",
    "        # pred_scores = pred_scores.clone().detach().requires_grad_(True)\n",
    "        # print(pred_scores)\n",
    "        pred_scores = torch.stack(pred_scores)\n",
    "        # print(pred_scores)\n",
    "        # break\n",
    "        # # Prepare pairs for MarginRankingLoss\n",
    "        # pairs = list(itertools.combinations(range(batch_size), 2))\n",
    "        # if not pairs:\n",
    "        #     continue  # Skip if less than 2 samples in batch\n",
    "\n",
    "        # pred1 = torch.stack([pred_scores[i] for i, j in pairs])\n",
    "        # pred2 = torch.stack([pred_scores[j] for i, j in pairs])\n",
    "        # dms1 = torch.stack([dms_scores[i] for i, j in pairs])\n",
    "        # dms2 = torch.stack([dms_scores[j] for i, j in pairs])\n",
    "\n",
    "        # # Determine target: 1 if dms1 > dms2, -1 if dms1 < dms2\n",
    "        # target = torch.sign(dms1 - dms2)\n",
    "        # non_zero_indices = target != 0\n",
    "        # if non_zero_indices.sum() == 0:\n",
    "        #     continue  # Skip if all targets are zero\n",
    "\n",
    "        # pred1 = pred1[non_zero_indices]\n",
    "        # pred2 = pred2[non_zero_indices]\n",
    "        # target = target[non_zero_indices]\n",
    "\n",
    "                # Compute predicted scores for each sample in the batch\n",
    "        # This assumes you have a way to map logits to predicted scores\n",
    "        # For example, summing log-probabilities of the correct tokens\n",
    "\n",
    "        # batch_size = pred_scores.size(0)\n",
    "\n",
    "        if batch_size > 1:\n",
    "            pred_mean = pred_scores.mean()\n",
    "            pred_std = pred_scores.std(unbiased=False)\n",
    "            pred_scores_std = (pred_scores - pred_mean) / (pred_std + 1e-8)\n",
    "\n",
    "            dms_mean = dms_scores.mean()\n",
    "            dms_std = dms_scores.std(unbiased=False)\n",
    "            dms_scores_std = (dms_scores - dms_mean) / (dms_std + 1e-8)\n",
    "\n",
    "            loss = loss_fn(pred_scores_std.view(-1), dms_scores_std.view(-1))\n",
    "        else:\n",
    "            # Handle batch size of 1 appropriately\n",
    "            # For example, you might skip the update or accumulate gradients over multiple batches\n",
    "            continue\n",
    "\n",
    "\n",
    "        # loss = loss_fn(pred1, pred2, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # Validation phase\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "\n",
    "    # break\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            dms_scores = batch['dms_score'].to(device)\n",
    "            mutants = batch['mutant']\n",
    "\n",
    "            batch_size = len(mutants)\n",
    "            pred_scores = []\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    ss_input_ids=ss_input_ids,\n",
    "                    labels=input_ids\n",
    "                )\n",
    "\n",
    "                logits = outputs.logits\n",
    "                logits = torch.log_softmax(logits[:, 1:-1, :], dim=-1)\n",
    "\n",
    "                pred_score = 0\n",
    "                for sub_mutant in mutants[i].split(\":\"):\n",
    "                    wt, idx, mt = sub_mutant[0], int(sub_mutant[1:-1]) - 1, sub_mutant[-1]\n",
    "                    score = logits[0, idx, tokenizer.convert_tokens_to_ids(mt)] - logits[0, idx, tokenizer.convert_tokens_to_ids(wt)]\n",
    "                    pred_score += score.item()\n",
    "                pred_scores.append(pred_score)\n",
    "\n",
    "            pred_scores = torch.tensor(pred_scores, device=device)\n",
    "\n",
    "            # Ensure batch size is greater than 1 to compute standard deviation\n",
    "            if pred_scores.size(0) > 1:\n",
    "                pred_mean = pred_scores.mean()\n",
    "                pred_std = pred_scores.std(unbiased=False)\n",
    "                pred_scores_std = (pred_scores - pred_mean) / (pred_std + 1e-8)\n",
    "\n",
    "                dms_mean = dms_scores.mean()\n",
    "                dms_std = dms_scores.std(unbiased=False)\n",
    "                dms_scores_std = (dms_scores - dms_mean) / (dms_std + 1e-8)\n",
    "\n",
    "                # Reshape tensors to ensure matching dimensions\n",
    "                pred_scores_std = pred_scores_std.view(-1)\n",
    "                dms_scores_std = dms_scores_std.view(-1)\n",
    "\n",
    "\n",
    "\n",
    "                loss = loss_fn(pred_scores_std, dms_scores_std)\n",
    "                \n",
    "                # print(loss.item())\n",
    "                val_losses.append(loss.item())\n",
    "            else:\n",
    "                # Skip this batch if batch size is 1\n",
    "                continue\n",
    "\n",
    "    avg_val_loss = sum(val_losses) / len(val_losses) if val_losses else float('nan')\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d6f5e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../model/prosst_finetuned_A0A2Z5U3Z0_9INFA_Wu_2014_epoch5/model/tokenizer_config.json',\n",
       " '../model/prosst_finetuned_A0A2Z5U3Z0_9INFA_Wu_2014_epoch5/model/special_tokens_map.json',\n",
       " '../model/prosst_finetuned_A0A2Z5U3Z0_9INFA_Wu_2014_epoch5/model/vocab.txt',\n",
       " '../model/prosst_finetuned_A0A2Z5U3Z0_9INFA_Wu_2014_epoch5/model/added_tokens.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"../model/prosst_finetuned_\"+name+\"_epoch\"+str(num_epochs)+\"/model\")\n",
    "tokenizer.save_pretrained(\"../model/prosst_finetuned_\"+name+\"_epoch\"+str(num_epochs)+\"/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc30bb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6e5cf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_less  = AutoModelForMaskedLM.from_pretrained(\"/home/yining_yang/Documents/lm/SSRAP/model/prosst_finetuned_A0A2Z5U3Z0_9INFA_Wu_2014_epoch5/model\", trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "857aef10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProSSTForMaskedLM(\n",
       "  (prosst): ProSSTModel(\n",
       "    (embeddings): ProSSTEmbeddings(\n",
       "      (word_embeddings): Embedding(25, 768, padding_idx=0)\n",
       "      (ss_embeddings): Embedding(2051, 768)\n",
       "      (ss_layer_norm): ProSSTLayerNorm()\n",
       "      (LayerNorm): ProSSTLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ProSSTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ProSSTLayer(\n",
       "          (attention): ProSSTAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (ss_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (ss_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ProSSTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): ProSSTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ProSSTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ProSSTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): ProSSTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(2048, 768)\n",
       "    )\n",
       "  )\n",
       "  (cls): ProSSTOnlyMLMHead(\n",
       "    (predictions): ProSSTLMPredictionHead(\n",
       "      (transform): ProSSTPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=25, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30fd34bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6deada4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method PeftAdapterMixin.enable_adapters of ProSSTForMaskedLM(\n",
       "  (prosst): ProSSTModel(\n",
       "    (embeddings): ProSSTEmbeddings(\n",
       "      (word_embeddings): Embedding(25, 768, padding_idx=0)\n",
       "      (ss_embeddings): Embedding(2051, 768)\n",
       "      (ss_layer_norm): ProSSTLayerNorm()\n",
       "      (LayerNorm): ProSSTLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ProSSTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ProSSTLayer(\n",
       "          (attention): ProSSTAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (ss_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (ss_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ProSSTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): ProSSTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ProSSTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ProSSTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): ProSSTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(2048, 768)\n",
       "    )\n",
       "  )\n",
       "  (cls): ProSSTOnlyMLMHead(\n",
       "    (predictions): ProSSTLMPredictionHead(\n",
       "      (transform): ProSSTPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=25, bias=False)\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.enable_adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3df985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
